Краткий репорт

Задача — автоматически классифицировать миллионы наименований ТРУ без готовой разметки. Основная проблема — шумные, короткие, неоднородные тексты, поэтому моделям нечему учиться напрямую.

Мы применили многоуровневое решение. На первом слое используется rule-based классификатор (жёсткие правила + якорные слова), который даёт точную базовую псевдоразметку и позволяет покрыть большую часть датасета. На втором слое мы обучили модель TF-IDF + SVM на очищенной части псевдолейблов, чтобы улучшить качество там, где правила не срабатывают. На третьем слое используется BERT как финальный уточняющий классификатор, который исправляет сложные, неоднозначные и редкие случаи.

Такое каскадное решение позволило надёжно разметить большой корпус данных и добиться высоких метрик на реальной задаче классификации ТРУ.

1 - rules покрыло 75.4% из всей выборки 

2 - TF-IDF + SVM - +2.23%    [EVAL] Accuracy: 0.9851 [EVAL] F1 (macro): 0.9682 [EVAL] F1 (weighted): 0.9854 относительно rules. F1 (из-за дисбаланса категорий).

3- сейчас Bert обучается. 

К сожалению на 3х - эпохах обучение занимает больше ожидаемого времени ~11 часов. НЕ успел полностью обучить модель, так и сохоранить веса. К сожалению не готов вам показать метрики и оутпут. Так же не успел собрать итоговый pipleline и основной класс FinalClassifier.


Хоть и реализовать не успел хочу описать методологию. Данные были не размеченны я решил сделать псевдоразметку. Заметил что в коротком опсиание товара, содержаться ключевые слова(название) ТРУ. Отталкиваясь от этого решил сделать rule-based. Количество категории было много и спектор широкий. outputs/top_keywords 
Закрыть с помошью rule-based больше 75% не получилось, начило теряться качество и в целом возможность масштабируемости. Второй слой TF-IDF + SVM. Подумал с разряжеными  матирицами лучше всего подайдет он. к тому же достаточно бысто и надежно без особой нагрузки на железо
Решить проблему контекста и сложных формулировок подумал лучше всего RuBERT. На момент обучение слоя Bert, 77.63% cтрок из всей выборки были псевдоразмеченны. Ясно что от этой псевдоразметки выского качество не стоит ожидпть, в силу шумов, спец.обозначений, абвиатур итд. Слой с BERT нужен что бы максимально много покрыть из оставшейся части не размеченной выборки. Так же поверх перыйх двух слойов проводить проверку.


Обработка и предварительная подготовка данных.
Мы используем трёхуровневый препроцессинг: очистку текста от артикулов, дат и спецсимволов, нормализацию и лемматизацию (Natasha или pymorphy3), чтобы привести описания ТРУ к чистому и единообразному виду для правил, SVM и BERT.
